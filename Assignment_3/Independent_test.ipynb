{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "result = pd.read_csv(\"C:/Users/ddes2/Desktop/桌面/BML/demo/Contest results_1226_update_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>組別</th>\n",
       "      <th>上傳筆數</th>\n",
       "      <th>有效筆數</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>FP</th>\n",
       "      <th>Precision</th>\n",
       "      <th>ACC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>F1</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>第03組.csv</td>\n",
       "      <td>5399</td>\n",
       "      <td>5399</td>\n",
       "      <td>360</td>\n",
       "      <td>4537</td>\n",
       "      <td>140</td>\n",
       "      <td>362</td>\n",
       "      <td>0.498615</td>\n",
       "      <td>0.907020</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.926107</td>\n",
       "      <td>0.589198</td>\n",
       "      <td>0.550289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>第04組.csv</td>\n",
       "      <td>5399</td>\n",
       "      <td>5399</td>\n",
       "      <td>260</td>\n",
       "      <td>4499</td>\n",
       "      <td>240</td>\n",
       "      <td>400</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.881460</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.918351</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.387923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>第07組.csv</td>\n",
       "      <td>5399</td>\n",
       "      <td>5399</td>\n",
       "      <td>269</td>\n",
       "      <td>4359</td>\n",
       "      <td>231</td>\n",
       "      <td>540</td>\n",
       "      <td>0.332509</td>\n",
       "      <td>0.857196</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.889773</td>\n",
       "      <td>0.411001</td>\n",
       "      <td>0.347434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>第01組.csv</td>\n",
       "      <td>5399</td>\n",
       "      <td>5399</td>\n",
       "      <td>391</td>\n",
       "      <td>2658</td>\n",
       "      <td>109</td>\n",
       "      <td>2241</td>\n",
       "      <td>0.148556</td>\n",
       "      <td>0.564734</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.542560</td>\n",
       "      <td>0.249681</td>\n",
       "      <td>0.188229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>第15組.csv</td>\n",
       "      <td>5399</td>\n",
       "      <td>5399</td>\n",
       "      <td>341</td>\n",
       "      <td>3066</td>\n",
       "      <td>159</td>\n",
       "      <td>1833</td>\n",
       "      <td>0.156854</td>\n",
       "      <td>0.631043</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.625842</td>\n",
       "      <td>0.255049</td>\n",
       "      <td>0.181958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>第09組.csv</td>\n",
       "      <td>5399</td>\n",
       "      <td>5399</td>\n",
       "      <td>440</td>\n",
       "      <td>1929</td>\n",
       "      <td>60</td>\n",
       "      <td>2970</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.438785</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.393754</td>\n",
       "      <td>0.225064</td>\n",
       "      <td>0.164515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>第05組.csv</td>\n",
       "      <td>5399</td>\n",
       "      <td>5399</td>\n",
       "      <td>322</td>\n",
       "      <td>2845</td>\n",
       "      <td>178</td>\n",
       "      <td>2054</td>\n",
       "      <td>0.135522</td>\n",
       "      <td>0.586590</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.580731</td>\n",
       "      <td>0.223922</td>\n",
       "      <td>0.131238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>第02組.csv</td>\n",
       "      <td>5399</td>\n",
       "      <td>5399</td>\n",
       "      <td>315</td>\n",
       "      <td>2858</td>\n",
       "      <td>185</td>\n",
       "      <td>2041</td>\n",
       "      <td>0.133701</td>\n",
       "      <td>0.587701</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.583384</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.124728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>第06組.csv</td>\n",
       "      <td>4916</td>\n",
       "      <td>4916</td>\n",
       "      <td>308</td>\n",
       "      <td>2883</td>\n",
       "      <td>192</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.132530</td>\n",
       "      <td>0.591035</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.588487</td>\n",
       "      <td>0.218130</td>\n",
       "      <td>0.119719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>第12組_幫他k+1.csv</td>\n",
       "      <td>4891</td>\n",
       "      <td>4891</td>\n",
       "      <td>351</td>\n",
       "      <td>2230</td>\n",
       "      <td>149</td>\n",
       "      <td>2669</td>\n",
       "      <td>0.116225</td>\n",
       "      <td>0.478051</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.455195</td>\n",
       "      <td>0.199432</td>\n",
       "      <td>0.091786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>第10組.csv</td>\n",
       "      <td>4475</td>\n",
       "      <td>4475</td>\n",
       "      <td>326</td>\n",
       "      <td>2053</td>\n",
       "      <td>174</td>\n",
       "      <td>2846</td>\n",
       "      <td>0.102774</td>\n",
       "      <td>0.440637</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.419065</td>\n",
       "      <td>0.177560</td>\n",
       "      <td>0.041847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>第11組_2.csv</td>\n",
       "      <td>3973</td>\n",
       "      <td>3973</td>\n",
       "      <td>235</td>\n",
       "      <td>2677</td>\n",
       "      <td>265</td>\n",
       "      <td>2222</td>\n",
       "      <td>0.095645</td>\n",
       "      <td>0.539359</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.546438</td>\n",
       "      <td>0.158945</td>\n",
       "      <td>0.009569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>第13組.csv</td>\n",
       "      <td>5399</td>\n",
       "      <td>5399</td>\n",
       "      <td>9</td>\n",
       "      <td>4816</td>\n",
       "      <td>491</td>\n",
       "      <td>83</td>\n",
       "      <td>0.097826</td>\n",
       "      <td>0.893684</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.983058</td>\n",
       "      <td>0.030405</td>\n",
       "      <td>0.002369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>第08組.csv</td>\n",
       "      <td>4702</td>\n",
       "      <td>4702</td>\n",
       "      <td>179</td>\n",
       "      <td>2392</td>\n",
       "      <td>321</td>\n",
       "      <td>2507</td>\n",
       "      <td>0.066642</td>\n",
       "      <td>0.476199</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.488263</td>\n",
       "      <td>0.112367</td>\n",
       "      <td>-0.089133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>第14組_幫他K+13.csv</td>\n",
       "      <td>4827</td>\n",
       "      <td>4827</td>\n",
       "      <td>0</td>\n",
       "      <td>4400</td>\n",
       "      <td>500</td>\n",
       "      <td>499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.814966</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.898142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.101949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>第14組.csv</td>\n",
       "      <td>4827</td>\n",
       "      <td>279</td>\n",
       "      <td>0</td>\n",
       "      <td>253</td>\n",
       "      <td>500</td>\n",
       "      <td>4646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046861</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.051643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.793548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>第12組.csv</td>\n",
       "      <td>4891</td>\n",
       "      <td>305</td>\n",
       "      <td>16</td>\n",
       "      <td>63</td>\n",
       "      <td>484</td>\n",
       "      <td>4836</td>\n",
       "      <td>0.003298</td>\n",
       "      <td>0.014632</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.012860</td>\n",
       "      <td>0.005979</td>\n",
       "      <td>-0.917597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>第11組.csv</td>\n",
       "      <td>3973</td>\n",
       "      <td>236</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>491</td>\n",
       "      <td>4866</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>0.007779</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.003349</td>\n",
       "      <td>-0.955010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 組別  上傳筆數  有效筆數   TP    TN   FN    FP  Precision       ACC  \\\n",
       "0          第03組.csv  5399  5399  360  4537  140   362   0.498615  0.907020   \n",
       "1          第04組.csv  5399  5399  260  4499  240   400   0.393939  0.881460   \n",
       "2          第07組.csv  5399  5399  269  4359  231   540   0.332509  0.857196   \n",
       "3          第01組.csv  5399  5399  391  2658  109  2241   0.148556  0.564734   \n",
       "4          第15組.csv  5399  5399  341  3066  159  1833   0.156854  0.631043   \n",
       "5          第09組.csv  5399  5399  440  1929   60  2970   0.129032  0.438785   \n",
       "6          第05組.csv  5399  5399  322  2845  178  2054   0.135522  0.586590   \n",
       "7          第02組.csv  5399  5399  315  2858  185  2041   0.133701  0.587701   \n",
       "8          第06組.csv  4916  4916  308  2883  192  2016   0.132530  0.591035   \n",
       "9    第12組_幫他k+1.csv  4891  4891  351  2230  149  2669   0.116225  0.478051   \n",
       "10         第10組.csv  4475  4475  326  2053  174  2846   0.102774  0.440637   \n",
       "11       第11組_2.csv  3973  3973  235  2677  265  2222   0.095645  0.539359   \n",
       "12         第13組.csv  5399  5399    9  4816  491    83   0.097826  0.893684   \n",
       "13         第08組.csv  4702  4702  179  2392  321  2507   0.066642  0.476199   \n",
       "14  第14組_幫他K+13.csv  4827  4827    0  4400  500   499   0.000000  0.814966   \n",
       "15         第14組.csv  4827   279    0   253  500  4646   0.000000  0.046861   \n",
       "16         第12組.csv  4891   305   16    63  484  4836   0.003298  0.014632   \n",
       "17         第11組.csv  3973   236    9    33  491  4866   0.001846  0.007779   \n",
       "\n",
       "    Sensitivity  Specificity        F1       MCC  \n",
       "0         0.720     0.926107  0.589198  0.550289  \n",
       "1         0.520     0.918351  0.448276  0.387923  \n",
       "2         0.538     0.889773  0.411001  0.347434  \n",
       "3         0.782     0.542560  0.249681  0.188229  \n",
       "4         0.682     0.625842  0.255049  0.181958  \n",
       "5         0.880     0.393754  0.225064  0.164515  \n",
       "6         0.644     0.580731  0.223922  0.131238  \n",
       "7         0.630     0.583384  0.220588  0.124728  \n",
       "8         0.616     0.588487  0.218130  0.119719  \n",
       "9         0.702     0.455195  0.199432  0.091786  \n",
       "10        0.652     0.419065  0.177560  0.041847  \n",
       "11        0.470     0.546438  0.158945  0.009569  \n",
       "12        0.018     0.983058  0.030405  0.002369  \n",
       "13        0.358     0.488263  0.112367 -0.089133  \n",
       "14        0.000     0.898142  0.000000 -0.101949  \n",
       "15        0.000     0.051643  0.000000 -0.793548  \n",
       "16        0.032     0.012860  0.005979 -0.917597  \n",
       "17        0.018     0.006736  0.003349 -0.955010  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['組別',\n",
       " '上傳筆數',\n",
       " '有效筆數',\n",
       " 'TP',\n",
       " 'TN',\n",
       " 'FN',\n",
       " 'FP',\n",
       " 'Precision',\n",
       " 'ACC',\n",
       " 'Sensitivity',\n",
       " 'Specificity',\n",
       " 'F1',\n",
       " 'MCC']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## idependent dataset處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0LLX5</td>\n",
       "      <td>MAKVGGITESAGSANSSEIDSLARFAVDEHNKKENACLEFSKVVNV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A4S4ET57</td>\n",
       "      <td>MNEFSPLLISSGRDRIPTPQSLPETPQFIPSSPLVNPNSLEASSDS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A4S4EB91</td>\n",
       "      <td>MIVLERRFLTIARCDAAKKSLSGYQYQSRRGFGHINFYGGDLQFKL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q94ID8</td>\n",
       "      <td>ISPKPEWRALMDEMAAVATKEYRSIVFQEARFVEYFRLATPELEYG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A5S6R7Q7</td>\n",
       "      <td>MANKAVTIGDLIHRVATSCLSNRLPGSYAVSDSGDTDFDDDDDDDP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>Q9C5J9</td>\n",
       "      <td>MKFWRERERENKEQILAPLCGQVRVLVVGDSGVGKTSLVHLINKGS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>Q6ZCF8</td>\n",
       "      <td>MLACFLPLVLIVLCFPKSSAPARINTGMSLFTVALLVVPVMDAVYV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>A0A4S4ENA5</td>\n",
       "      <td>MEIDPGLVTQPSELVTREEPLISLAPAGRVGKKWKKIARSQIGDFG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>Q8RV74</td>\n",
       "      <td>MKLHFVLRFLFGPVPVYFSALAILILLTNAQYFGLVGVTVPRATKL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>Q8GXF7</td>\n",
       "      <td>MPGNHSEISLNEQNRVDDNDTKTKTTTRKKKKKKDVTIVDDDDNQF...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>422 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                           Sequence\n",
       "0        C0LLX5  MAKVGGITESAGSANSSEIDSLARFAVDEHNKKENACLEFSKVVNV...\n",
       "1    A0A4S4ET57  MNEFSPLLISSGRDRIPTPQSLPETPQFIPSSPLVNPNSLEASSDS...\n",
       "2    A0A4S4EB91  MIVLERRFLTIARCDAAKKSLSGYQYQSRRGFGHINFYGGDLQFKL...\n",
       "3        Q94ID8  ISPKPEWRALMDEMAAVATKEYRSIVFQEARFVEYFRLATPELEYG...\n",
       "4    A0A5S6R7Q7  MANKAVTIGDLIHRVATSCLSNRLPGSYAVSDSGDTDFDDDDDDDP...\n",
       "..          ...                                                ...\n",
       "417      Q9C5J9  MKFWRERERENKEQILAPLCGQVRVLVVGDSGVGKTSLVHLINKGS...\n",
       "418      Q6ZCF8  MLACFLPLVLIVLCFPKSSAPARINTGMSLFTVALLVVPVMDAVYV...\n",
       "419  A0A4S4ENA5  MEIDPGLVTQPSELVTREEPLISLAPAGRVGKKWKKIARSQIGDFG...\n",
       "420      Q8RV74  MKLHFVLRFLFGPVPVYFSALAILILLTNAQYFGLVGVTVPRATKL...\n",
       "421      Q8GXF7  MPGNHSEISLNEQNRVDDNDTKTKTTTRKKKKKKDVTIVDDDDNQF...\n",
       "\n",
       "[422 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/independent_test_1226.csv\")\n",
    "# 之後要寫的fasta檔案\n",
    "independent_predata = open(\"C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/independent_predata.txt\", \"w\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_id = data[\"ID\"]\n",
    "whole_seq = data[\"Sequence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(15)\n",
    "length = int(n*2+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 抓K的位子，且長度為31\n",
    "# k_id = []\n",
    "# k_index = []\n",
    "# # k_seq = []\n",
    "# for i in range(0,len(whole_seq)):\n",
    "#     each_seq = whole_seq[i]\n",
    "#     for pos in range(0,len(each_seq)):\n",
    "#         if each_seq[pos] == \"K\" and len(each_seq[pos-n:pos+n+1])== length :\n",
    "#             independent_predata.write('>' + str(each_id[i]) + '_' + str(pos+1) + \"\\n\" + each_seq[pos-n:pos+n+1]+ \"\\n\")\n",
    "#             k_id.append(each_id[i])\n",
    "#             k_index.append(pos+1)\n",
    "#             # k_seq.append(each_seq[pos-n:pos+n+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_id = []\n",
    "k_index = []\n",
    "# k_seq = []\n",
    "for i in range(0, len(whole_seq)):\n",
    "    each_seq = whole_seq[i]\n",
    "    for pos in range(0, len(each_seq)):\n",
    "        if each_seq[pos] == \"K\":\n",
    "            seq_start = max(pos - n, 0)  # 確保切片起始點不小於 0\n",
    "            seq_end = min(pos + n + 1, len(each_seq))  # 確保切片終點不超過序列長度\n",
    "            extracted_seq = each_seq[seq_start:seq_end]\n",
    "\n",
    "            # 檢查提取的序列長度，並根據需要在前後補充 'X'\n",
    "            while len(extracted_seq) < 31:\n",
    "                if seq_start > 0:\n",
    "                    extracted_seq = 'X' + extracted_seq\n",
    "                    seq_start -= 1\n",
    "                if len(extracted_seq) < 31 and seq_end < len(each_seq):\n",
    "                    extracted_seq += 'X'\n",
    "                    seq_end += 1\n",
    "\n",
    "            # 將序列寫入檔案並添加到清單\n",
    "            independent_predata.write('>' + str(each_id[i]) + '_' + str(pos + 1) + \"\\n\" + extracted_seq + \"\\n\")\n",
    "            k_id.append(each_id[i])\n",
    "            k_index.append(pos + 1)\n",
    "            # k_seq.append(extracted_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k_id</th>\n",
       "      <th>k_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0LLX5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C0LLX5</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C0LLX5</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C0LLX5</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C0LLX5</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5394</th>\n",
       "      <td>Q8GXF7</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>Q8GXF7</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396</th>\n",
       "      <td>Q8GXF7</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>Q8GXF7</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>Q8GXF7</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5399 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        k_id  k_index\n",
       "0     C0LLX5        3\n",
       "1     C0LLX5       32\n",
       "2     C0LLX5       33\n",
       "3     C0LLX5       42\n",
       "4     C0LLX5       47\n",
       "...      ...      ...\n",
       "5394  Q8GXF7       65\n",
       "5395  Q8GXF7       66\n",
       "5396  Q8GXF7       68\n",
       "5397  Q8GXF7       71\n",
       "5398  Q8GXF7       78\n",
       "\n",
       "[5399 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 偷看抓K的結果\n",
    "new_data = pd.DataFrame({\n",
    "    \"k_id\": k_id,\n",
    "    \"k_index\": k_index,\n",
    "    # \"k_seq\": k_seq\n",
    "})\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_predata.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 連iFeature的功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'iFeature' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Superzchen/iFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ddes2\\\\Desktop\\\\桌面\\\\BML\\\\Assignment_3'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptor type: EAAC\n"
     ]
    }
   ],
   "source": [
    "!python C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/iFeature/iFeature.py --file C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/independent_predata.txt --type EAAC --out C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/test_EAAC.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>SW.1.A</th>\n",
       "      <th>SW.1.C</th>\n",
       "      <th>SW.1.D</th>\n",
       "      <th>SW.1.E</th>\n",
       "      <th>SW.1.F</th>\n",
       "      <th>SW.1.G</th>\n",
       "      <th>SW.1.H</th>\n",
       "      <th>SW.1.I</th>\n",
       "      <th>SW.1.K</th>\n",
       "      <th>...</th>\n",
       "      <th>SW.27.M</th>\n",
       "      <th>SW.27.N</th>\n",
       "      <th>SW.27.P</th>\n",
       "      <th>SW.27.Q</th>\n",
       "      <th>SW.27.R</th>\n",
       "      <th>SW.27.S</th>\n",
       "      <th>SW.27.T</th>\n",
       "      <th>SW.27.V</th>\n",
       "      <th>SW.27.W</th>\n",
       "      <th>SW.27.Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0LLX5_3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C0LLX5_32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C0LLX5_33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C0LLX5_42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C0LLX5_47</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 541 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           #  SW.1.A  SW.1.C  SW.1.D  SW.1.E  SW.1.F  SW.1.G  SW.1.H  SW.1.I  \\\n",
       "0   C0LLX5_3     0.2     0.0     0.0     0.0     0.0     0.2     0.0     0.0   \n",
       "1  C0LLX5_32     0.0     0.0     0.2     0.2     0.0     0.0     0.0     0.2   \n",
       "2  C0LLX5_33     0.0     0.0     0.2     0.2     0.0     0.0     0.0     0.2   \n",
       "3  C0LLX5_42     0.0     0.0     0.2     0.2     0.0     0.0     0.2     0.0   \n",
       "4  C0LLX5_47     0.2     0.0     0.0     0.2     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   SW.1.K  ...  SW.27.M  SW.27.N  SW.27.P  SW.27.Q  SW.27.R  SW.27.S  SW.27.T  \\\n",
       "0     0.2  ...      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1     0.0  ...      0.0      0.2      0.0      0.0      0.0      0.0      0.0   \n",
       "2     0.0  ...      0.0      0.2      0.0      0.2      0.0      0.0      0.0   \n",
       "3     0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0      0.2   \n",
       "4     0.4  ...      0.0      0.0      0.0      0.0      0.0      0.0      0.2   \n",
       "\n",
       "   SW.27.V  SW.27.W  SW.27.Y  \n",
       "0      0.0      0.0      0.0  \n",
       "1      0.6      0.0      0.0  \n",
       "2      0.4      0.0      0.0  \n",
       "3      0.2      0.0      0.4  \n",
       "4      0.0      0.0      0.0  \n",
       "\n",
       "[5 rows x 541 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EAAC = pd.read_csv(\"C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/test_EAAC.txt\", sep=\"\\t\")\n",
    "EAAC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Load the new dataset\n",
    "# EAAC = pd.read_csv(\"C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/test_EAAC.txt\", sep = \"\\t\")\n",
    "\n",
    "# # Preprocess the data as per the original training data's preprocessing\n",
    "# # For example, if you need to scale your features:\n",
    "# scaler = StandardScaler()\n",
    "# new_data_scaled = scaler.fit_transform(EAAC) \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "EAAC = pd.read_csv(\"C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/test_EAAC.txt\", sep=\"\\t\")\n",
    "\n",
    "# Identify non-numeric columns\n",
    "non_numeric_columns = EAAC.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Here, you need to decide whether to drop these columns or convert them\n",
    "# For example, to drop them:\n",
    "EAAC_numeric = EAAC.drop(non_numeric_columns, axis=1)\n",
    "\n",
    "# Preprocess the data\n",
    "scaler = StandardScaler()\n",
    "new_data_scaled = scaler.fit_transform(EAAC_numeric)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>SW.1.A</th>\n",
       "      <th>SW.1.C</th>\n",
       "      <th>SW.1.D</th>\n",
       "      <th>SW.1.E</th>\n",
       "      <th>SW.1.F</th>\n",
       "      <th>SW.1.G</th>\n",
       "      <th>SW.1.H</th>\n",
       "      <th>SW.1.I</th>\n",
       "      <th>SW.1.K</th>\n",
       "      <th>...</th>\n",
       "      <th>SW.27.M</th>\n",
       "      <th>SW.27.N</th>\n",
       "      <th>SW.27.P</th>\n",
       "      <th>SW.27.Q</th>\n",
       "      <th>SW.27.R</th>\n",
       "      <th>SW.27.S</th>\n",
       "      <th>SW.27.T</th>\n",
       "      <th>SW.27.V</th>\n",
       "      <th>SW.27.W</th>\n",
       "      <th>SW.27.Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0LLX5_3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C0LLX5_32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C0LLX5_33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C0LLX5_42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C0LLX5_47</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 541 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           #  SW.1.A  SW.1.C  SW.1.D  SW.1.E  SW.1.F  SW.1.G  SW.1.H  SW.1.I  \\\n",
       "0   C0LLX5_3     0.2     0.0     0.0     0.0     0.0     0.2     0.0     0.0   \n",
       "1  C0LLX5_32     0.0     0.0     0.2     0.2     0.0     0.0     0.0     0.2   \n",
       "2  C0LLX5_33     0.0     0.0     0.2     0.2     0.0     0.0     0.0     0.2   \n",
       "3  C0LLX5_42     0.0     0.0     0.2     0.2     0.0     0.0     0.2     0.0   \n",
       "4  C0LLX5_47     0.2     0.0     0.0     0.2     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   SW.1.K  ...  SW.27.M  SW.27.N  SW.27.P  SW.27.Q  SW.27.R  SW.27.S  SW.27.T  \\\n",
       "0     0.2  ...      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1     0.0  ...      0.0      0.2      0.0      0.0      0.0      0.0      0.0   \n",
       "2     0.0  ...      0.0      0.2      0.0      0.2      0.0      0.0      0.0   \n",
       "3     0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0      0.2   \n",
       "4     0.4  ...      0.0      0.0      0.0      0.0      0.0      0.0      0.2   \n",
       "\n",
       "   SW.27.V  SW.27.W  SW.27.Y  \n",
       "0      0.0      0.0      0.0  \n",
       "1      0.6      0.0      0.0  \n",
       "2      0.4      0.0      0.0  \n",
       "3      0.2      0.0      0.4  \n",
       "4      0.0      0.0      0.0  \n",
       "\n",
       "[5 rows x 541 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EAAC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>SW.1.A</th>\n",
       "      <th>SW.1.C</th>\n",
       "      <th>SW.1.D</th>\n",
       "      <th>SW.1.E</th>\n",
       "      <th>SW.1.F</th>\n",
       "      <th>SW.1.G</th>\n",
       "      <th>SW.1.H</th>\n",
       "      <th>SW.1.I</th>\n",
       "      <th>SW.1.K</th>\n",
       "      <th>...</th>\n",
       "      <th>SW.27.M</th>\n",
       "      <th>SW.27.N</th>\n",
       "      <th>SW.27.P</th>\n",
       "      <th>SW.27.Q</th>\n",
       "      <th>SW.27.R</th>\n",
       "      <th>SW.27.S</th>\n",
       "      <th>SW.27.T</th>\n",
       "      <th>SW.27.V</th>\n",
       "      <th>SW.27.W</th>\n",
       "      <th>SW.27.Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0LLX5_3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C0LLX5_32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C0LLX5_33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C0LLX5_42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C0LLX5_47</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 541 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           #  SW.1.A  SW.1.C  SW.1.D  SW.1.E  SW.1.F  SW.1.G  SW.1.H  SW.1.I  \\\n",
       "0   C0LLX5_3     0.2     0.0     0.0     0.0     0.0     0.2     0.0     0.0   \n",
       "1  C0LLX5_32     0.0     0.0     0.2     0.2     0.0     0.0     0.0     0.2   \n",
       "2  C0LLX5_33     0.0     0.0     0.2     0.2     0.0     0.0     0.0     0.2   \n",
       "3  C0LLX5_42     0.0     0.0     0.2     0.2     0.0     0.0     0.2     0.0   \n",
       "4  C0LLX5_47     0.2     0.0     0.0     0.2     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   SW.1.K  ...  SW.27.M  SW.27.N  SW.27.P  SW.27.Q  SW.27.R  SW.27.S  SW.27.T  \\\n",
       "0     0.2  ...      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1     0.0  ...      0.0      0.2      0.0      0.0      0.0      0.0      0.0   \n",
       "2     0.0  ...      0.0      0.2      0.0      0.2      0.0      0.0      0.0   \n",
       "3     0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0      0.2   \n",
       "4     0.4  ...      0.0      0.0      0.0      0.0      0.0      0.0      0.2   \n",
       "\n",
       "   SW.27.V  SW.27.W  SW.27.Y  \n",
       "0      0.0      0.0      0.0  \n",
       "1      0.6      0.0      0.0  \n",
       "2      0.4      0.0      0.0  \n",
       "3      0.2      0.0      0.4  \n",
       "4      0.0      0.0      0.0  \n",
       "\n",
       "[5 rows x 541 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_EAAC = pd.DataFrame(EAAC)\n",
    "df_EAAC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_EAAC.to_csv(\"C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/test_EAAC.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv('C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/test_EAAC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>#</th>\n",
       "      <th>SW.1.A</th>\n",
       "      <th>SW.1.C</th>\n",
       "      <th>SW.1.D</th>\n",
       "      <th>SW.1.E</th>\n",
       "      <th>SW.1.F</th>\n",
       "      <th>SW.1.G</th>\n",
       "      <th>SW.1.H</th>\n",
       "      <th>SW.1.I</th>\n",
       "      <th>...</th>\n",
       "      <th>SW.27.M</th>\n",
       "      <th>SW.27.N</th>\n",
       "      <th>SW.27.P</th>\n",
       "      <th>SW.27.Q</th>\n",
       "      <th>SW.27.R</th>\n",
       "      <th>SW.27.S</th>\n",
       "      <th>SW.27.T</th>\n",
       "      <th>SW.27.V</th>\n",
       "      <th>SW.27.W</th>\n",
       "      <th>SW.27.Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>C0LLX5_3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>C0LLX5_32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>C0LLX5_33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>C0LLX5_42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>C0LLX5_47</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5394</th>\n",
       "      <td>5394</td>\n",
       "      <td>Q8GXF7_65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>5395</td>\n",
       "      <td>Q8GXF7_66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396</th>\n",
       "      <td>5396</td>\n",
       "      <td>Q8GXF7_68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>5397</td>\n",
       "      <td>Q8GXF7_71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>5398</td>\n",
       "      <td>Q8GXF7_78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5399 rows × 542 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0          #  SW.1.A  SW.1.C  SW.1.D  SW.1.E  SW.1.F  SW.1.G  \\\n",
       "0              0   C0LLX5_3     0.2     0.0     0.0     0.0     0.0     0.2   \n",
       "1              1  C0LLX5_32     0.0     0.0     0.2     0.2     0.0     0.0   \n",
       "2              2  C0LLX5_33     0.0     0.0     0.2     0.2     0.0     0.0   \n",
       "3              3  C0LLX5_42     0.0     0.0     0.2     0.2     0.0     0.0   \n",
       "4              4  C0LLX5_47     0.2     0.0     0.0     0.2     0.0     0.0   \n",
       "...          ...        ...     ...     ...     ...     ...     ...     ...   \n",
       "5394        5394  Q8GXF7_65     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "5395        5395  Q8GXF7_66     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "5396        5396  Q8GXF7_68     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "5397        5397  Q8GXF7_71     0.0     0.0     0.0     0.0     0.2     0.0   \n",
       "5398        5398  Q8GXF7_78     0.0     0.0     0.0     0.0     0.2     0.0   \n",
       "\n",
       "      SW.1.H  SW.1.I  ...  SW.27.M  SW.27.N  SW.27.P  SW.27.Q  SW.27.R  \\\n",
       "0        0.0     0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
       "1        0.0     0.2  ...      0.0      0.2      0.0      0.0      0.0   \n",
       "2        0.0     0.2  ...      0.0      0.2      0.0      0.2      0.0   \n",
       "3        0.2     0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
       "4        0.0     0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
       "...      ...     ...  ...      ...      ...      ...      ...      ...   \n",
       "5394     0.0     0.0  ...      0.0      0.0      0.0      0.0      0.2   \n",
       "5395     0.0     0.0  ...      0.0      0.0      0.0      0.0      0.2   \n",
       "5396     0.0     0.0  ...      0.0      0.0      0.0      0.0      0.2   \n",
       "5397     0.0     0.0  ...      0.2      0.0      0.0      0.0      0.4   \n",
       "5398     0.0     0.0  ...      0.0      0.0      0.0      0.0      0.4   \n",
       "\n",
       "      SW.27.S  SW.27.T  SW.27.V  SW.27.W  SW.27.Y  \n",
       "0         0.0      0.0      0.0      0.0      0.0  \n",
       "1         0.0      0.0      0.6      0.0      0.0  \n",
       "2         0.0      0.0      0.4      0.0      0.0  \n",
       "3         0.0      0.2      0.2      0.0      0.4  \n",
       "4         0.0      0.2      0.0      0.0      0.0  \n",
       "...       ...      ...      ...      ...      ...  \n",
       "5394      0.2      0.0      0.0      0.0      0.0  \n",
       "5395      0.0      0.0      0.0      0.0      0.0  \n",
       "5396      0.0      0.0      0.0      0.0      0.0  \n",
       "5397      0.0      0.0      0.2      0.0      0.0  \n",
       "5398      0.0      0.0      0.0      0.0      0.0  \n",
       "\n",
       "[5399 rows x 542 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the trained LightGBM model\n",
    "lgbm_model = joblib.load('C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/trained_lgbm_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features_ is 540 and input n_features is 542",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m predictions \u001b[38;5;241m=\u001b[39m lgbm_model\u001b[38;5;241m.\u001b[39mpredict(new_data)\n\u001b[0;32m      5\u001b[0m labels \u001b[38;5;241m=\u001b[39m (predictions \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m      7\u001b[0m new_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m labels\n",
      "File \u001b[1;32mc:\\Users\\ddes2\\anaconda3\\Lib\\site-packages\\lightgbm\\sklearn.py:1178\u001b[0m, in \u001b[0;36mLGBMClassifier.predict\u001b[1;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1168\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1175\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m   1176\u001b[0m ):\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_proba(\n\u001b[0;32m   1179\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   1180\u001b[0m         raw_score\u001b[38;5;241m=\u001b[39mraw_score,\n\u001b[0;32m   1181\u001b[0m         start_iteration\u001b[38;5;241m=\u001b[39mstart_iteration,\n\u001b[0;32m   1182\u001b[0m         num_iteration\u001b[38;5;241m=\u001b[39mnum_iteration,\n\u001b[0;32m   1183\u001b[0m         pred_leaf\u001b[38;5;241m=\u001b[39mpred_leaf,\n\u001b[0;32m   1184\u001b[0m         pred_contrib\u001b[38;5;241m=\u001b[39mpred_contrib,\n\u001b[0;32m   1185\u001b[0m         validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[0;32m   1186\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1187\u001b[0m     )\n\u001b[0;32m   1188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objective) \u001b[38;5;129;01mor\u001b[39;00m raw_score \u001b[38;5;129;01mor\u001b[39;00m pred_leaf \u001b[38;5;129;01mor\u001b[39;00m pred_contrib:\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\ddes2\\anaconda3\\Lib\\site-packages\\lightgbm\\sklearn.py:1208\u001b[0m, in \u001b[0;36mLGBMClassifier.predict_proba\u001b[1;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[0;32m   1196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\n\u001b[0;32m   1197\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1198\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1205\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m   1206\u001b[0m ):\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is set after definition, using a template.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m   1209\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   1210\u001b[0m         raw_score\u001b[38;5;241m=\u001b[39mraw_score,\n\u001b[0;32m   1211\u001b[0m         start_iteration\u001b[38;5;241m=\u001b[39mstart_iteration,\n\u001b[0;32m   1212\u001b[0m         num_iteration\u001b[38;5;241m=\u001b[39mnum_iteration,\n\u001b[0;32m   1213\u001b[0m         pred_leaf\u001b[38;5;241m=\u001b[39mpred_leaf,\n\u001b[0;32m   1214\u001b[0m         pred_contrib\u001b[38;5;241m=\u001b[39mpred_contrib,\n\u001b[0;32m   1215\u001b[0m         validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[0;32m   1216\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1217\u001b[0m     )\n\u001b[0;32m   1218\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objective) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (raw_score \u001b[38;5;129;01mor\u001b[39;00m pred_leaf \u001b[38;5;129;01mor\u001b[39;00m pred_contrib):\n\u001b[0;32m   1219\u001b[0m         _log_warning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot compute class probabilities or labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1220\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdue to the usage of customized objective function.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1221\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning raw scores instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ddes2\\anaconda3\\Lib\\site-packages\\lightgbm\\sklearn.py:894\u001b[0m, in \u001b[0;36mLGBMModel.predict\u001b[1;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[0;32m    892\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features \u001b[38;5;241m!=\u001b[39m n_features:\n\u001b[1;32m--> 894\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of features of the model must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    895\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatch the input. Model n_features_ is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    896\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput n_features is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    897\u001b[0m \u001b[38;5;66;03m# retrive original params that possibly can be used in both training and prediction\u001b[39;00m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;66;03m# and then overwrite them (considering aliases) with params that were passed directly in prediction\u001b[39;00m\n\u001b[0;32m    899\u001b[0m predict_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_params(stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features_ is 540 and input n_features is 542"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "predictions = lgbm_model.predict(new_data)\n",
    "labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "new_data['label'] = labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "data = pd.read_csv('C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/test_EAAC.csv')  \n",
    "\n",
    "xgb_model = joblib.load('C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/trained_xgb_model.pkl') \n",
    "\n",
    "features = data.drop(columns=['Unnamed: 0', '#'])\n",
    "predictions = xgb_model.predict(features)\n",
    "\n",
    "labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "data['label'] = labels\n",
    "\n",
    "data.to_csv('C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/predicted_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/predicted_results_cleaned.csv'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the predicted results CSV file\n",
    "predicted_results_path = 'C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/predicted_results.csv'\n",
    "predicted_data = pd.read_csv(predicted_results_path)\n",
    "\n",
    "# Remove 'Unnamed' column and columns from 'C' to 'TV'\n",
    "# Assuming 'C' to 'TV' are consecutive columns\n",
    "# We will first find the positions of 'C' and 'TV' in the DataFrame\n",
    "start_col = predicted_data.columns.get_loc(\"SW.1.A\")\n",
    "end_col = predicted_data.columns.get_loc(\"SW.27.Y\")\n",
    "\n",
    "# Now, drop the columns\n",
    "predicted_data_cleaned = predicted_data.drop(predicted_data.columns[start_col:end_col + 1], axis=1)\n",
    "\n",
    "# Also dropping any 'Unnamed' columns which are typically generated from index columns in CSV\n",
    "predicted_data_cleaned = predicted_data_cleaned.loc[:, ~predicted_data_cleaned.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "cleaned_file_path = 'C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/predicted_results_cleaned.csv'\n",
    "predicted_data_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "cleaned_file_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:#: object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 13\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# dataset_path = '/mnt/data/test_EAAC.csv'\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# data = pd.read_csv(dataset_path)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Perform predictions\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m predictions \u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mpredict(predicted_data_cleaned)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Convert predictions to 0 (negative) and 1 (positive)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Assuming that positive prediction corresponds to class label 1\u001b[39;00m\n\u001b[0;32m     17\u001b[0m labels \u001b[38;5;241m=\u001b[39m (predictions \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ddes2\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1553\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1544\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m   1545\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1546\u001b[0m     X: ArrayLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1550\u001b[0m     iteration_range: Optional[Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1551\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[1;32m-> 1553\u001b[0m         class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m   1554\u001b[0m             X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   1555\u001b[0m             output_margin\u001b[38;5;241m=\u001b[39moutput_margin,\n\u001b[0;32m   1556\u001b[0m             validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[0;32m   1557\u001b[0m             base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[0;32m   1558\u001b[0m             iteration_range\u001b[38;5;241m=\u001b[39miteration_range,\n\u001b[0;32m   1559\u001b[0m         )\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_margin:\n\u001b[0;32m   1561\u001b[0m             \u001b[38;5;66;03m# If output_margin is active, simply return the scores\u001b[39;00m\n\u001b[0;32m   1562\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m class_probs\n",
      "File \u001b[1;32mc:\\Users\\ddes2\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1168\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1168\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_booster()\u001b[38;5;241m.\u001b[39minplace_predict(\n\u001b[0;32m   1169\u001b[0m             data\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   1170\u001b[0m             iteration_range\u001b[38;5;241m=\u001b[39miteration_range,\n\u001b[0;32m   1171\u001b[0m             predict_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmargin\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_margin \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1172\u001b[0m             missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1173\u001b[0m             base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[0;32m   1174\u001b[0m             validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[0;32m   1175\u001b[0m         )\n\u001b[0;32m   1176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[0;32m   1177\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ddes2\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:2416\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2414\u001b[0m     data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m   2415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pandas_df(data):\n\u001b[1;32m-> 2416\u001b[0m     data, fns, _ \u001b[38;5;241m=\u001b[39m _transform_pandas_df(data, enable_categorical)\n\u001b[0;32m   2417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m validate_features:\n\u001b[0;32m   2418\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(fns)\n",
      "File \u001b[1;32mc:\\Users\\ddes2\\anaconda3\\Lib\\site-packages\\xgboost\\data.py:490\u001b[0m, in \u001b[0;36m_transform_pandas_df\u001b[1;34m(data, enable_categorical, feature_names, feature_types, meta, meta_type)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dtype \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtypes:\n\u001b[0;32m    484\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m    485\u001b[0m         (dtype\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m _pandas_dtype_mapper)\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m is_pd_sparse_dtype(dtype)\n\u001b[0;32m    487\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (is_pd_cat_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m enable_categorical)\n\u001b[0;32m    488\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m is_pa_ext_dtype(dtype)\n\u001b[0;32m    489\u001b[0m     ):\n\u001b[1;32m--> 490\u001b[0m         _invalid_dataframe_dtype(data)\n\u001b[0;32m    491\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_pa_ext_dtype(dtype):\n\u001b[0;32m    492\u001b[0m         pyarrow_extension \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ddes2\\anaconda3\\Lib\\site-packages\\xgboost\\data.py:308\u001b[0m, in \u001b[0;36m_invalid_dataframe_dtype\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    306\u001b[0m type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame.dtypes for data must be int, float, bool or category.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_err\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_ENABLE_CAT_ERR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m--> 308\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:#: object"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "# dataset_path = '/mnt/data/test_EAAC.csv'\n",
    "# data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Load the trained LightGBM model\n",
    "# model_path = '/mnt/data/trained_lgbm_model.pkl'\n",
    "# lgbm_model = joblib.load(model_path)\n",
    "\n",
    "# Perform predictions\n",
    "predictions = xgb_model.predict(new_data)\n",
    "\n",
    "# Convert predictions to 0 (negative) and 1 (positive)\n",
    "# Assuming that positive prediction corresponds to class label 1\n",
    "labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Append the 'label' column to the dataset\n",
    "data['label'] = labels\n",
    "data.head()  # Display the first few rows of the dataset with the new column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Load the new dataset\n",
    "# new_data = pd.read_csv('C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/test_EAAC.csv')\n",
    "\n",
    "# Identify non-numeric columns\n",
    "non_numeric_parts = new_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Here, you need to decide whether to drop these columns or convert them\n",
    "# For example, to drop them:\n",
    "EAAC_numeric_parts = EAAC.drop(non_numeric_parts, axis=1)\n",
    "\n",
    "# Preprocess the data\n",
    "scaler = StandardScaler()\n",
    "new_data_scaled = scaler.fit_transform(EAAC_numeric_parts)\n",
    "\n",
    "\n",
    "# # Preprocess the data as per the original training data's preprocessing\n",
    "# # For example, if you need to scale your features:\n",
    "# scaler = StandardScaler()\n",
    "# new_data_scaled = scaler.fit_transform(new_data)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming EAAC_numeric is your original DataFrame with numeric columns only\n",
    "EAAC_numeric_scaled = pd.DataFrame(new_data_scaled, columns=EAAC_numeric.columns)\n",
    "\n",
    "# Make predictions\n",
    "predictions = lgbm_model.predict(EAAC_numeric_scaled)\n",
    "\n",
    "# Append predictions to the DataFrame\n",
    "EAAC_numeric_scaled['Predicted_Label'] = predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame with the predictions to a new CSV\n",
    "EAAC_numeric_scaled.to_csv('C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/lgbm_model.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save the DataFrame with the predictions to a new CSV\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m new_data_scaled\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/ddes2/Desktop/桌面/BML/Assignment_3/lgbm_model.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame with the predictions to a new CSV\n",
    "new_data_scaled.to_csv('C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/lgbm_model.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "data = pd.read_csv('C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/test_EAAC.csv')  \n",
    "\n",
    "xgb_model = joblib.load('C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/trained_xgb_model.pkl') \n",
    "\n",
    "features = data.drop(columns=['Unnamed: 0', '#'])\n",
    "predictions = xgb_model.predict(features)\n",
    "\n",
    "labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "data['label'] = labels\n",
    "\n",
    "data.to_csv('C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/predicted_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/predicted_results_cleaned.csv'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the predicted results CSV file\n",
    "predicted_results_path = 'C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/predicted_results.csv'\n",
    "predicted_data = pd.read_csv(predicted_results_path)\n",
    "\n",
    "# Remove 'Unnamed' column and columns from 'C' to 'TV'\n",
    "# Assuming 'C' to 'TV' are consecutive columns\n",
    "# We will first find the positions of 'C' and 'TV' in the DataFrame\n",
    "start_col = predicted_data.columns.get_loc(\"SW.1.A\")\n",
    "end_col = predicted_data.columns.get_loc(\"SW.27.Y\")\n",
    "\n",
    "# Now, drop the columns\n",
    "predicted_data_cleaned = predicted_data.drop(predicted_data.columns[start_col:end_col + 1], axis=1)\n",
    "\n",
    "# Also dropping any 'Unnamed' columns which are typically generated from index columns in CSV\n",
    "predicted_data_cleaned = predicted_data_cleaned.loc[:, ~predicted_data_cleaned.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "cleaned_file_path = 'C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/predicted_results_cleaned.csv'\n",
    "predicted_data_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "cleaned_file_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ddes2\\AppData\\Local\\Temp\\ipykernel_20252\\1506713855.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_data.rename(columns={'label': 'Label'}, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/XGB.csv'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the cleaned predicted results CSV file\n",
    "cleaned_results_path = 'C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/predicted_results_cleaned.csv'\n",
    "cleaned_data = pd.read_csv(cleaned_results_path)\n",
    "\n",
    "# The ID and Position seem to be combined in one column, we will split them\n",
    "# Assuming the format of the ID_Position is consistent and looks like 'ID_Position'\n",
    "# We will create two new columns by splitting the '#' column\n",
    "cleaned_data[['ID', 'Position']] = cleaned_data['#'].str.split('_', expand=True)\n",
    "\n",
    "# Drop the original '#' column and any other unnecessary columns\n",
    "final_data = cleaned_data[['ID', 'Position', 'label']]\n",
    "\n",
    "# Rename 'label' column to 'Label' to match the case in the provided image\n",
    "final_data.rename(columns={'label': 'Label'}, inplace=True)\n",
    "\n",
    "# Save the final data to a new CSV file\n",
    "final_formatted_file_path = 'C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/XGB.csv'\n",
    "final_data.to_csv(final_formatted_file_path, index=False)\n",
    "\n",
    "final_formatted_file_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the trained LightGBM model\n",
    "xgb_model = joblib.load('trained_xgb_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the new dataset\n",
    "new_data = pd.read_csv('C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/test_EAAC.csv')\n",
    "\n",
    "# Preprocess the data as per the original training data's preprocessing\n",
    "# For example, if you need to scale your features:\n",
    "scaler = StandardScaler()\n",
    "new_data_scaled = scaler.fit_transform(new_data)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = xgb_model.predict(new_data_scaled)\n",
    "\n",
    "# Append predictions to the original DataFrame\n",
    "new_data_scaled['Predicted_Label'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame with the predictions to a new CSV\n",
    "new_data_scaled.to_csv('C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/xgb_model.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ddes2\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "data = pd.read_csv('C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/test_EAAC.csv')  \n",
    "\n",
    "gbc_model = joblib.load('C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/trained_gbc_model.pkl') \n",
    "\n",
    "features = data.drop(columns=['Unnamed: 0', '#'])\n",
    "predictions = gbc_model.predict(features)\n",
    "\n",
    "labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "data['label'] = labels\n",
    "\n",
    "data.to_csv('C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/predicted_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the predicted results CSV file\n",
    "predicted_results_path = 'C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/predicted_results.csv'\n",
    "predicted_data = pd.read_csv(predicted_results_path)\n",
    "\n",
    "# Remove 'Unnamed' column and columns from 'C' to 'TV'\n",
    "# Assuming 'C' to 'TV' are consecutive columns\n",
    "# We will first find the positions of 'C' and 'TV' in the DataFrame\n",
    "start_col = predicted_data.columns.get_loc(\"SW.1.A\")\n",
    "end_col = predicted_data.columns.get_loc(\"SW.27.Y\")\n",
    "\n",
    "# Now, drop the columns\n",
    "predicted_data_cleaned = predicted_data.drop(predicted_data.columns[start_col:end_col + 1], axis=1)\n",
    "\n",
    "# Also dropping any 'Unnamed' columns which are typically generated from index columns in CSV\n",
    "predicted_data_cleaned = predicted_data_cleaned.loc[:, ~predicted_data_cleaned.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "cleaned_file_path = 'C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/predicted_results_cleaned.csv'\n",
    "predicted_data_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "cleaned_file_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned predicted results CSV file\n",
    "cleaned_results_path = 'C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/predicted_results_cleaned.csv'\n",
    "cleaned_data = pd.read_csv(cleaned_results_path)\n",
    "\n",
    "# The ID and Position seem to be combined in one column, we will split them\n",
    "# Assuming the format of the ID_Position is consistent and looks like 'ID_Position'\n",
    "# We will create two new columns by splitting the '#' column\n",
    "cleaned_data[['ID', 'Position']] = cleaned_data['#'].str.split('_', expand=True)\n",
    "\n",
    "# Drop the original '#' column and any other unnecessary columns\n",
    "final_data = cleaned_data[['ID', 'Position', 'label']]\n",
    "\n",
    "# Rename 'label' column to 'Label' to match the case in the provided image\n",
    "final_data.rename(columns={'label': 'Label'}, inplace=True)\n",
    "\n",
    "# Save the final data to a new CSV file\n",
    "final_formatted_file_path = 'C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/XGB.csv'\n",
    "final_data.to_csv(final_formatted_file_path, index=False)\n",
    "\n",
    "final_formatted_file_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the trained LightGBM model\n",
    "gbc_model = joblib.load('trained_gbc_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the new dataset\n",
    "new_data = pd.read_csv('C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/test_EAAC.csv')\n",
    "\n",
    "# Preprocess the data as per the original training data's preprocessing\n",
    "# For example, if you need to scale your features:\n",
    "scaler = StandardScaler()\n",
    "new_data_scaled = scaler.fit_transform(new_data)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = gbc_model.predict(new_data_scaled)\n",
    "\n",
    "# Append predictions to the original DataFrame\n",
    "new_data_scaled['Predicted_Label'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame with the predictions to a new CSV\n",
    "new_data_scaled.to_csv('C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/gb_model.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "model_path = 'C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/CNN_model.h5'  \n",
    "CNN_model = load_model(model_path)\n",
    "\n",
    "# Load the new dataset\n",
    "new_data = pd.read_csv('C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/test_EAAC.csv')\n",
    "\n",
    "# Preprocess the data as per the original training data's preprocessing\n",
    "# For example, if you need to scale your features:\n",
    "scaler = StandardScaler()\n",
    "new_data_scaled = scaler.fit_transform(new_data)  \n",
    "\n",
    "# Make Prediction\n",
    "predictions = CNN_model.predict(new_data_scaled)\n",
    "\n",
    "\n",
    "# Append predictions to the original DataFrame\n",
    "new_data_scaled['Predicted_Label'] = predictions\n",
    "\n",
    "# Save the DataFrame with the predictions to a new CSV\n",
    "new_data_scaled.to_csv('C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/cnn_model.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Load the trained LightGBM model\n",
    "catboost_model = joblib.load('trained_catboost_model.pkl')\n",
    "\n",
    "\n",
    "# Load the new dataset\n",
    "new_data = pd.read_csv('C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/test_EAAC.csv')\n",
    "\n",
    "# Preprocess the data as per the original training data's preprocessing\n",
    "# For example, if you need to scale your features:\n",
    "scaler = StandardScaler()\n",
    "new_data_scaled = scaler.fit_transform(new_data)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = catboost_model.predict(new_data_scaled)\n",
    "\n",
    "# Append predictions to the original DataFrame\n",
    "new_data_scaled['Predicted_Label'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame with the predictions to a new CSV\n",
    "new_data_scaled.to_csv('C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/catboost_model.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 統計數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from catboost import CatBoostClassifier\n",
    "# CatBoost_clf=CatBoostClassifier()\n",
    "# CatBoost_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = pd.read_csv(\"C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/testfile.csv\")\n",
    "\n",
    "\n",
    "# # CatBoost_ind_lable = CatBoost_clf.predict(ind_feature)\n",
    "# # LGBM_ind_lable = lgbm_model.predict(ind_feature)\n",
    "# # GBC_ind_lable = gbc_model.predict(ind_feature)\n",
    "# # final_prediction = np.where(ensemble_labels > 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "# read all the files\n",
    "file_paths = glob('C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/*_model.csv')\n",
    "dataframes = [pd.read_csv(fp) for fp in file_paths if 'label' in pd.read_csv(fp).columns]\n",
    "\n",
    "# make sure every files has column \"label\"\n",
    "if not all(df.shape[0] == dataframes[0].shape[0] for df in dataframes):\n",
    "    raise ValueError(\"Files do not have the same number of rows or missing 'label' column.\")\n",
    "\n",
    "# count the numbers of 1 and 0\n",
    "majority_labels = []\n",
    "for row in range(dataframes[0].shape[0]):\n",
    "    row_labels = [df.loc[row, 'label'] for df in dataframes]\n",
    "    majority_label = 1 if sum(row_labels) > len(row_labels) / 2 else 0\n",
    "    majority_labels.append(majority_label)\n",
    "\n",
    "# Create a new dataframe\n",
    "new_df = dataframes[0].drop(columns='label')\n",
    "new_df['label'] = majority_labels\n",
    "\n",
    "# save the new files\n",
    "new_file_path = 'C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/new_file.csv'  \n",
    "new_df.to_csv(new_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 廢 code\n",
    "\n",
    "# import pandas as pd\n",
    "# from glob import glob\n",
    "\n",
    "# # glob mode\n",
    "# file_paths = glob('C:/Users/ddes2/Desktop/桌面/BML/Assignment_3/*_model.csv')  \n",
    "\n",
    "# # Initiate Counter = 0\n",
    "# count_0 = 0\n",
    "# count_1 = 0\n",
    "\n",
    "# # Deal with the files\n",
    "# for file_path in file_paths:\n",
    "#     # read csv\n",
    "#     df = pd.read_csv(file_path)\n",
    "\n",
    "#     # make sure \"label\" exist\n",
    "#     if 'label' in df.columns:\n",
    "#         # count the number of 0 and 1\n",
    "#         count_0 += (df['label'] == 0).sum()\n",
    "#         count_1 += (df['label'] == 1).sum()\n",
    "        \n",
    "#         majority_label = 1 if count_1 > count_0 else 0\n",
    "#         df['label'] = majority_label\n",
    "        \n",
    "#         new_file_path = file_path.replace('.csv', '_modified.csv')\n",
    "#         df.to_csv(new_file_path, index=False)\n",
    "\n",
    "# # print the results\n",
    "# # print(f\"Count of 0: {count_0}\")\n",
    "# # print(f\"Count of 1: {count_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       ID  Position  Label\n",
       " 0  C0LLX5         3      0\n",
       " 1  C0LLX5        32      0\n",
       " 2  C0LLX5        33      1\n",
       " 3  C0LLX5        42      1\n",
       " 4  C0LLX5        47      0,\n",
       "        ID  Position  Label\n",
       " 0  C0LLX5         3      1\n",
       " 1  C0LLX5        32      0\n",
       " 2  C0LLX5        33      0\n",
       " 3  C0LLX5        42      0\n",
       " 4  C0LLX5        47      0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the two CSV files to compare their labels\n",
    "file_path_lgbm = \"C:/Users/ddes2/Downloads/LGBM.csv\"\n",
    "file_path_group = \"C:/Users/ddes2/Desktop/桌面/BML/Demo/processed_independent_answer.csv\"\n",
    "\n",
    "# Since the encoding could be an issue, we'll try the same approach as before\n",
    "try:\n",
    "    # Try reading with default encoding\n",
    "    df_lgbm = pd.read_csv(file_path_lgbm)\n",
    "    df_group = pd.read_csv(file_path_group)\n",
    "except UnicodeDecodeError:\n",
    "    # If default reading fails, try with 'ISO-8859-1' encoding\n",
    "    df_lgbm = pd.read_csv(file_path_lgbm, encoding='ISO-8859-1')\n",
    "    df_group = pd.read_csv(file_path_group, encoding='ISO-8859-1')\n",
    "\n",
    "# Check the first few rows to understand the structure of these files\n",
    "df_lgbm_head = df_lgbm.head()\n",
    "df_group_head = df_group.head()\n",
    "\n",
    "(df_lgbm_head, df_group_head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Position</th>\n",
       "      <th>Label_lgbm</th>\n",
       "      <th>Label_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0LLX5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C0LLX5</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C0LLX5</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C0LLX5</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C0LLX5</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5387</th>\n",
       "      <td>Q8GXF7</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388</th>\n",
       "      <td>Q8GXF7</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>Q8GXF7</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5392</th>\n",
       "      <td>Q8GXF7</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>Q8GXF7</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2320 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Position  Label_lgbm  Label_group\n",
       "0     C0LLX5         3           0            1\n",
       "2     C0LLX5        33           1            0\n",
       "3     C0LLX5        42           1            0\n",
       "6     C0LLX5        69           1            0\n",
       "7     C0LLX5        74           1            0\n",
       "...      ...       ...         ...          ...\n",
       "5387  Q8GXF7        31           1            0\n",
       "5388  Q8GXF7        32           1            0\n",
       "5390  Q8GXF7        34           1            0\n",
       "5392  Q8GXF7        56           1            0\n",
       "5397  Q8GXF7        71           1            0\n",
       "\n",
       "[2320 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since there's a typo in the column name 'Lable' in df_group, we'll correct it to 'Label'\n",
    "df_group.rename(columns={'Lable': 'Label'}, inplace=True)\n",
    "\n",
    "# Merging the two dataframes on 'ID' and 'Position' to compare their 'Label' columns\n",
    "df_merged = pd.merge(df_lgbm, df_group, on=['ID', 'Position'], suffixes=('_lgbm', '_group'))\n",
    "\n",
    "# Finding the rows where the labels differ\n",
    "df_differences = df_merged[df_merged['Label_lgbm'] != df_merged['Label_group']]\n",
    "\n",
    "# Showing the rows where the labels differ\n",
    "df_differences[['ID', 'Position', 'Label_lgbm', 'Label_group']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 處理正確答案的 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path_independent_test = 'C:/Users/ddes2/Desktop/桌面/BML/Demo/independent_test_answer_1226.csv'\n",
    "df_independent_test = pd.read_csv(file_path_independent_test)\n",
    "\n",
    "# Correct the column names if needed\n",
    "df_independent_test.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "\n",
    "# Initialize an empty list to store the processed data\n",
    "processed_data = []\n",
    "\n",
    "for index, row in df_independent_test.iterrows():\n",
    "    # Extract and process positive positions if not NaN\n",
    "    if pd.notna(row['positive']):\n",
    "        positive_positions = eval(row['positive'])\n",
    "        for pos in positive_positions:\n",
    "            processed_data.append({'ID': row['ID'], 'Position': pos, 'Label': 1})\n",
    "    \n",
    "    # Extract and process negative positions if not NaN\n",
    "    if pd.notna(row['negative']):\n",
    "        negative_positions = eval(row['negative'])\n",
    "        for pos in negative_positions:\n",
    "            processed_data.append({'ID': row['ID'], 'Position': pos, 'Label': 0})\n",
    "\n",
    "# Convert the processed data into a DataFrame\n",
    "df_processed = pd.DataFrame(processed_data, columns=['ID', 'Position', 'Label'])\n",
    "\n",
    "# Save the processed DataFrame to a CSV file\n",
    "processed_file_path = 'C:/Users/ddes2/Desktop/桌面/BML/Demo/processed_independent_answer.csv'\n",
    "df_processed.to_csv(processed_file_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
